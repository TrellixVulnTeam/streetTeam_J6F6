{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import datetime\n",
    "import time as Time\n",
    "from posixpath import commonpath, splitext\n",
    "from bs4.element import NavigableString\n",
    "from dateutil.parser import parse\n",
    "from sys import excepthook\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import uuid\n",
    "import re\n",
    "from requests import exceptions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next decide which urls to scrape and put them into an array so you can iterate through them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#URL's to be scrapped\n",
    "url1 = 'https://www.rubyselixir.com/events/'\n",
    "url2 = ''\n",
    "url3 = ''\n",
    "url4 = ''\n",
    "url5 = ''\n",
    "url_array = [url1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that will iterate through the url_array and scrape webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Properties\n",
    "venue_name = \"Ruby's Elixir\"\n",
    "band_name = ''\n",
    "date_string = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scape_urls(arr):\n",
    "    for i in arr:\n",
    "        response = requests.get(i).text\n",
    "        soup = BeautifulSoup(response, 'lxml')\n",
    "\n",
    "        for single_Show in soup.find_all('div', class_='stevent-wrap'):\n",
    "\n",
    "            try:\n",
    "                #Grab its information and organize it\n",
    "                #Date\n",
    "                date_Div = single_Show.find('div', class_ = 'stevent-date')\n",
    "                month = date_Div.find('div', class_ = 'date-top')\n",
    "                day = date_Div.find('div', class_ = 'date-middle')\n",
    "                month_And_Day_And_Year = month.text + \" \" + day.text + \",\" + \" \" + \"2021\"\n",
    "\n",
    "                #Band\n",
    "                band_name = single_Show.find('div', class_ = 'stevent-title').h3.text\n",
    "\n",
    "                #Start Time\n",
    "                start_Time = single_Show.find('div', class_ = 'stevent-starttime').text\n",
    "                remove_Words_Time = start_Time.replace('Starts at ', '')\n",
    "                remove_Space_Time = remove_Words_Time.replace(' ', '')\n",
    "\n",
    "                whole_Date = month_And_Day_And_Year + \" \" + remove_Space_Time\n",
    "                date = parse(whole_Date)\n",
    "                date_string = '{:%b %d, %Y %-I:%M%p}'.format(date)\n",
    "\n",
    "                showDict = {}\n",
    "                showDict['band'] = band_name\n",
    "                showDict['dateString'] = date_string\n",
    "\n",
    "                array.append(showDict)\n",
    "\n",
    "            except AttributeError as ex:\n",
    "                print('Error', ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = []\n",
    "scape_urls(url_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "#Export as JSON\n",
    "venDict = {}\n",
    "venDict['venueName'] = venue_name\n",
    "venDict['shows'] = array\n",
    "\n",
    "venue_array = [venDict]\n",
    "finalDict = {}\n",
    "finalDict['venue'] = venue_array\n",
    "\n",
    "#Save To json file\n",
    "save_path = '/Users/nathanhedgeman/Documents/Scrappers/Show Data'\n",
    "file_name = venue_name + '.json'\n",
    "complete_name = os.path.join(save_path, file_name)\n",
    "\n",
    "file = open(complete_name, 'w')\n",
    "file.write(json.dumps(finalDict, indent = 2))\n",
    "file.close()\n",
    "print(\"Complete!\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('python@3.9')",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
